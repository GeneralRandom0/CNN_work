{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T06:44:17.338038Z","iopub.execute_input":"2021-07-16T06:44:17.338453Z","iopub.status.idle":"2021-07-16T06:44:17.357896Z","shell.execute_reply.started":"2021-07-16T06:44:17.33842Z","shell.execute_reply":"2021-07-16T06:44:17.356495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport scipy.io\nimport scipy.misc\nimport numpy as np\nimport pandas as pd\nimport PIL\nfrom PIL import ImageFont, ImageDraw, Image\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.python.framework.ops import EagerTensor","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:24.141711Z","iopub.execute_input":"2021-07-16T06:44:24.142126Z","iopub.status.idle":"2021-07-16T06:44:24.151116Z","shell.execute_reply.started":"2021-07-16T06:44:24.142076Z","shell.execute_reply":"2021-07-16T06:44:24.150272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo_head(feats, anchors, num_classes):\n    # Function by Adam Zellener\n    num_anchors = len(anchors)\n    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n    # Static implementation for fixed models.\n    # TODO: Remove or add option for static implementation.\n    # _, conv_height, conv_width, _ = K.int_shape(feats)\n    # conv_dims = K.variable([conv_width, conv_height])\n    # Dynamic implementation of conv dims for fully convolutional model.\n    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n    # In YOLO the height index is the inner most iteration.\n    conv_height_index = K.arange(0, stop=conv_dims[0])\n    conv_width_index = K.arange(0, stop=conv_dims[1])\n    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n\n    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n    conv_width_index = K.tile(\n        K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n    conv_width_index = K.flatten(K.transpose(conv_width_index))\n    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n    conv_index = K.cast(conv_index, K.dtype(feats))\n\n    feats = K.reshape(\n        feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n\n    # Static generation of conv_index:\n    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n    # conv_index = K.variable(\n    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n    # feats = Reshape(\n    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n\n    box_xy = K.sigmoid(feats[..., :2])\n    box_wh = K.exp(feats[..., 2:4])\n    box_confidence = K.sigmoid(feats[..., 4:5])\n    box_class_probs = K.softmax(feats[..., 5:])\n\n    # Adjust preditions to each spatial grid point and anchor size.\n    # Note: YOLO iterates over height index before width index.\n    box_xy = (box_xy + conv_index) / conv_dims\n    box_wh = box_wh * anchors_tensor / conv_dims\n\n    return box_xy, box_wh, box_confidence, box_class_probs","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:25.912964Z","iopub.execute_input":"2021-07-16T06:44:25.915079Z","iopub.status.idle":"2021-07-16T06:44:25.928201Z","shell.execute_reply.started":"2021-07-16T06:44:25.915034Z","shell.execute_reply":"2021-07-16T06:44:25.926698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imghdr\nimport colorsys\nimport random\nfrom tensorflow.keras import backend as K\nfrom functools import reduce\n\ndef preprocess_image(img_path, model_image_size):\n    image_type = imghdr.what(img_path)\n    image = Image.open(img_path)\n    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n    image_data = np.array(resized_image, dtype='float32')\n    image_data /= 255.\n    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n    return image, image_data\n\ndef compose(*funcs):\n    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n\n    Reference: https://mathieularose.com/function-composition-in-python/\n    \"\"\"\n    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n    if funcs:\n        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n    else:\n        raise ValueError('Composition of empty sequence not supported.')\n\ndef read_classes(classes_path):\n    with open(classes_path) as f:\n        class_names = f.readlines()\n    class_names = [c.strip() for c in class_names]\n    return class_names\n\ndef read_anchors(anchors_path):\n    with open(anchors_path) as f:\n        anchors = f.readline()\n        anchors = [float(x) for x in anchors.split(',')]\n        anchors = np.array(anchors).reshape(-1, 2)\n    return anchors\n\ndef scale_boxes(boxes, image_shape):\n    height = float(image_shape[0])\n    width = float(image_shape[1])\n    image_dims = K.stack([height, width, height, width])\n    image_dims = K.reshape(image_dims, [1, 4])\n    boxes = boxes * image_dims\n    return boxes\n\ndef get_colors_for_classes(num_classes):\n    if (hasattr(get_colors_for_classes, \"colors\") and\n            len(get_colors_for_classes.colors) == num_classes):\n        return get_colors_for_classes.colors\n\n    hsv_tuples = [(x / num_classes, 1., 1.) for x in range(num_classes)]\n    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n    colors = list(\n        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n            colors))\n    random.seed(10101)  # Fixed seed for consistent colors across runs.\n    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n    random.seed(None)  # Reset seed to default.\n    get_colors_for_classes.colors = colors  # Save colors for future calls.\n    return colors\n\n\ndef draw_boxes(image, boxes, box_classes, class_names, scores=None):\n    font = ImageFont.truetype(\n        font='/kaggle/input/fontyolo/FiraMono-Medium.otf',\n        size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n    thickness = (image.size[0] + image.size[1]) // 300\n\n    colors = get_colors_for_classes(len(class_names))\n    for i, c in list(enumerate(box_classes)):\n        box_class = class_names[c]\n        box = boxes[i]       \n        if isinstance(scores.numpy(), np.ndarray):\n            score = scores.numpy()[i]\n            label = '{} {:.2f}'.format(box_class, score)\n        else:\n            label = '{}'.format(box_class)\n        draw = ImageDraw.Draw(image)\n        label_size = draw.textsize(label, font)\n        top, left, bottom, right = box\n        top = max(0, np.floor(top + 0.5).astype('int32'))\n        left = max(0, np.floor(left + 0.5).astype('int32'))\n        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n        print(label, (left, top), (right, bottom))\n        if top - label_size[1] >= 0:\n            text_origin = np.array([left, top - label_size[1]])\n        else:\n            text_origin = np.array([left, top + 1])\n        for i in range(thickness):\n            draw.rectangle(\n                [left + i, top + i, right - i, bottom - i], outline=colors[c])\n        draw.rectangle(\n            [tuple(text_origin), tuple(text_origin + label_size)],\n            fill=colors[c])\n        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n        del draw\n\n    return np.array(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:52:16.557377Z","iopub.execute_input":"2021-07-16T06:52:16.557798Z","iopub.status.idle":"2021-07-16T06:52:16.587434Z","shell.execute_reply.started":"2021-07-16T06:52:16.557765Z","shell.execute_reply":"2021-07-16T06:52:16.586412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = .6):\n    box_scores = box_confidence*box_class_probs\n    box_classes = tf.math.argmax(box_scores,axis=-1)\n    box_class_scores = tf.math.reduce_max(box_scores,axis=-1)\n    filtering_mask = box_class_scores>=threshold\n    scores = tf.boolean_mask(box_class_scores,filtering_mask)\n    boxes = tf.boolean_mask(boxes,filtering_mask)\n    classes = tf.boolean_mask(box_classes,filtering_mask)\n    return scores, boxes, classes","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:33.755398Z","iopub.execute_input":"2021-07-16T06:44:33.755827Z","iopub.status.idle":"2021-07-16T06:44:33.765443Z","shell.execute_reply.started":"2021-07-16T06:44:33.755786Z","shell.execute_reply":"2021-07-16T06:44:33.76403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')     # tensor to be used in tf.image.non_max_suppression()\n    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold)\n    scores = tf.gather(scores,nms_indices)\n    boxes = tf.gather(boxes,nms_indices)\n    classes = tf.gather(classes,nms_indices)\n    return scores, boxes, classes","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:37.04861Z","iopub.execute_input":"2021-07-16T06:44:37.049189Z","iopub.status.idle":"2021-07-16T06:44:37.056192Z","shell.execute_reply.started":"2021-07-16T06:44:37.049153Z","shell.execute_reply":"2021-07-16T06:44:37.05546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo_boxes_to_corners(box_xy, box_wh):\n    box_mins = box_xy - (box_wh / 2.)\n    box_maxes = box_xy + (box_wh / 2.)\n    return tf.keras.backend.concatenate([\n        box_mins[..., 1:2],  # y_min\n        box_mins[..., 0:1],  # x_min\n        box_maxes[..., 1:2],  # y_max\n        box_maxes[..., 0:1]  # x_max\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:40.148767Z","iopub.execute_input":"2021-07-16T06:44:40.14946Z","iopub.status.idle":"2021-07-16T06:44:40.155619Z","shell.execute_reply.started":"2021-07-16T06:44:40.149406Z","shell.execute_reply":"2021-07-16T06:44:40.154474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n    boxes = yolo_boxes_to_corners(box_xy,box_wh)\n    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, score_threshold)\n    boxes = scale_boxes(boxes, image_shape)\n    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)\n    return scores, boxes, classes","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:42.177205Z","iopub.execute_input":"2021-07-16T06:44:42.177601Z","iopub.status.idle":"2021-07-16T06:44:42.188549Z","shell.execute_reply.started":"2021-07-16T06:44:42.177571Z","shell.execute_reply":"2021-07-16T06:44:42.186635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = read_classes(\"/kaggle/input/model-data/coco_classes.txt\")\nanchors = read_anchors(\"/kaggle/input/model-data/yolo_anchors.txt\")\nmodel_image_size = (608, 608) # Same as yolo_model input layer size","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:45.356456Z","iopub.execute_input":"2021-07-16T06:44:45.356865Z","iopub.status.idle":"2021-07-16T06:44:45.371572Z","shell.execute_reply.started":"2021-07-16T06:44:45.356832Z","shell.execute_reply":"2021-07-16T06:44:45.370173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo_model = load_model(\"/kaggle/input/yolov2/\", compile=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:44:54.964279Z","iopub.execute_input":"2021-07-16T06:44:54.964641Z","iopub.status.idle":"2021-07-16T06:45:02.202738Z","shell.execute_reply.started":"2021-07-16T06:44:54.96461Z","shell.execute_reply":"2021-07-16T06:45:02.201777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:45:18.635042Z","iopub.execute_input":"2021-07-16T06:45:18.635673Z","iopub.status.idle":"2021-07-16T06:45:18.683137Z","shell.execute_reply.started":"2021-07-16T06:45:18.635619Z","shell.execute_reply":"2021-07-16T06:45:18.681784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(image_file):\n    image, image_data = preprocess_image(\"/kaggle/input/imagesyolo/\" + image_file, model_image_size = (608, 608))\n    yolo_model_outputs = yolo_model(image_data)\n    yolo_outputs = yolo_head(yolo_model_outputs, anchors, len(class_names))  \n    out_scores, out_boxes, out_classes = yolo_eval(yolo_outputs, [image.size[1],  image.size[0]], 10, 0.3, 0.5)\n    print('Found {} boxes for {}'.format(len(out_boxes), \"images/\" + image_file))\n    colors = get_colors_for_classes(len(class_names))\n    draw_boxes(image, out_boxes, out_classes, class_names, out_scores)\n    image.save(os.path.join(\"/kaggle\", image_file), quality=100)\n    output_image = Image.open(os.path.join(\"/kaggle\", image_file))\n    imshow(output_image)\n    return out_scores, out_boxes, out_classes","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:54:30.429905Z","iopub.execute_input":"2021-07-16T06:54:30.430308Z","iopub.status.idle":"2021-07-16T06:54:30.440084Z","shell.execute_reply.started":"2021-07-16T06:54:30.430274Z","shell.execute_reply":"2021-07-16T06:54:30.438736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_scores, out_boxes, out_classes = predict(\"0002.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-07-16T06:54:55.617105Z","iopub.execute_input":"2021-07-16T06:54:55.617506Z","iopub.status.idle":"2021-07-16T06:54:56.92557Z","shell.execute_reply.started":"2021-07-16T06:54:55.617471Z","shell.execute_reply":"2021-07-16T06:54:56.924405Z"},"trusted":true},"execution_count":null,"outputs":[]}]}